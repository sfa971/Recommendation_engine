# -*- coding: utf-8 -*-
"""Recommendation_system_Mickael_Maya_Franck

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14I6_DUNa0ydFOasQ4eD2eU4aiICbCuGh
"""

# Commented out IPython magic to ensure Python compatibility.
# importation des modules
# %matplotlib inline
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import warnings

from keras.layers import Input, Embedding, Flatten, Dot, Dense
from keras.models import Model

warnings.filterwarnings('ignore')

# Téléchargements des CSV
!wget https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/ratings.csv
!wget https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/books.csv
!wget https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/book_tags.csv
!wget https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/tags.csv

ratings = pd.read_csv( 'ratings.csv' )
books = pd.read_csv( 'books.csv' )
tags = pd.read_csv( 'tags.csv' )
book_tags = pd.read_csv( 'book_tags.csv')

# Afficher les livres avec les meilleures notes
best_ratings_count = books[['goodreads_book_id','title','original_title','average_rating','ratings_count']]
best_ratings_count = best_ratings_count.sort_values(by=["average_rating"], ascending=False)

# Afficher les livres avec le plus de commentaires
best_text_reviews_count = books[['goodreads_book_id','title','original_title','average_rating','work_text_reviews_count']]
best_text_reviews_count = best_text_reviews_count.sort_values(by=["work_text_reviews_count"], ascending=False)

best_ratings_count.head(5)

best_text_reviews_count.head(5)

from sklearn.model_selection import train_test_split

train, test = train_test_split(ratings, test_size=0.2, random_state=42)

# Récupération du nombre d'utilisateurs et de livres
user_max = len(ratings.user_id.unique())
books_max = len(ratings.book_id.unique())

from keras.layers import Concatenate

# creating book embedding path
book_input = Input(shape=[1], name="Book-Input")
book_embedding = Embedding(books_max+1, 5, name="Book-Embedding")(book_input)
book_vec = Flatten(name="Flatten-Books")(book_embedding)

# creating user embedding path
user_input = Input(shape=[1], name="User-Input")
user_embedding = Embedding(user_max+1, 5, name="User-Embedding")(user_input)
user_vec = Flatten(name="Flatten-Users")(user_embedding)

# concatenate features
conc = Concatenate()([book_vec, user_vec])

# add fully-connected-layers
fc1 = Dense(128, activation='relu')(conc)
fc2 = Dense(32, activation='relu')(fc1)
out = Dense(1)(fc2)

# Create model and compile it
model = Model([user_input, book_input], out)
model.compile('adam', 'mean_squared_error')

from keras.models import load_model

if os.path.exists('regression_model2.h5'):
    model = load_model('regression_model2.h5')
else:
    history = model.fit([train.user_id, train.book_id], train.rating, epochs=5, verbose=1)
    model.save('regression_model2.h5')

model.evaluate([test.user_id, test.book_id], test.rating)

predictions = model.predict([test.user_id.head(10), test.book_id.head(10)])

# Making recommendations for the first user
book_data = np.array(list(set(ratings.book_id)))
user = np.array([1 for i in range(len(book_data))])

predictions = model.predict([user, book_data])

predictions = np.array([a[0] for a in predictions])

recommended_book_ids = (-predictions).argsort()[:20]

recommended_book = books[books['book_id'].isin(recommended_book_ids)]

recommended_book = recommended_book.sort_values(by=["average_rating"], ascending=False)

recommended_book['original_publication_year'] = recommended_book['original_publication_year'].astype(int)

recommended_book.head(1)

recommended_book = recommended_book.loc[:,['title','authors','original_publication_year','average_rating','work_text_reviews_count']]

recommended_book

